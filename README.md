# mlp_basic: Foundational Deep Learning with Multi-Layer Perceptrons

```bash
This repository is a collection of carefully implemented **Multi-Layer Perceptron (MLP)** projects
designed to showcase core deep learning principles using various frameworks, including **NumPy (from scratch)**,
**PyTorch**, and **TensorFlow**.

Whether you're looking to understand MLPs deeply, demonstrate clean DL project structure, or compare behaviors across
platforms â€” this repo is built for clarity, correctness, and completeness.
```
---

## Purpose

```bash
The goal of this repository is to demonstrate:

- A deep understanding of MLP architecture, optimization, and training behavior
- Framework-agnostic implementation of the same architecture using:
  - NumPy (fully manual)
  - PyTorch
  - TensorFlow
- Modular code structure aligned with real-world ML workflows
- Clear visualizations, loss tracking, and accuracy reporting
```
---


## Each subdirectory is a self-contained, standalone project with:

```bash

- `demo.ipynb` (interactive walkthrough)
- `demo_script.py` (script for CLI usage)
- Modular code: `models`, `utils`, `training`
- Evaluation, visualizations, and clear metrics
```
---

## Setup

Each project has its own `requirements.txt`. For example:

```bash
cd mlp_from_scratch
pip install -r requirements.txt
```
---
